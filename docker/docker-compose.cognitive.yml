services:
  cognitive-server:
    image: "${METABONK_COGNITIVE_IMAGE:-metabonk-cognitive-server:latest}"
    build:
      context: ../docker/cognitive-server
      dockerfile: Dockerfile
    container_name: "${METABONK_COGNITIVE_CONTAINER:-metabonk-cognitive-server}"
    restart: unless-stopped
    network_mode: host
    gpus: all
    security_opt:
      - label=disable

    # Requires nvidia-container-toolkit.
    environment:
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-0}
      - TZ=UTC
      - METABONK_RL_LOG_DIR=/app/logs/rl_training
      - METABONK_COGNITIVE_MOCK=${METABONK_COGNITIVE_MOCK:-0}
      - METABONK_PURE_VISION_MODE=${METABONK_PURE_VISION_MODE:-1}
      - METABONK_COGNITIVE_PROMPT_MODE=${METABONK_COGNITIVE_PROMPT_MODE:-}
      - METABONK_COGNITIVE_BACKEND=${METABONK_COGNITIVE_BACKEND:-}
      - METABONK_COGNITIVE_ATTN_IMPL=${METABONK_COGNITIVE_ATTN_IMPL:-flash_attention_2}
      - METABONK_COGNITIVE_MAX_CONCURRENCY=${METABONK_COGNITIVE_MAX_CONCURRENCY:-1}
      - METABONK_COGNITIVE_MAX_NEW_TOKENS=${METABONK_COGNITIVE_MAX_NEW_TOKENS:-64}
      - METABONK_COGNITIVE_TILE_EDGE=${METABONK_COGNITIVE_TILE_EDGE:-224}
      - METABONK_COGNITIVE_TILE_EDGE_MENU=${METABONK_COGNITIVE_TILE_EDGE_MENU:-}
      - METABONK_COGNITIVE_MENU_SINGLE_FRAME=${METABONK_COGNITIVE_MENU_SINGLE_FRAME:-1}
      - METABONK_COGNITIVE_ALWAYS_SINGLE_FRAME=${METABONK_COGNITIVE_ALWAYS_SINGLE_FRAME:-0}
      - METABONK_COGNITIVE_ENABLE_TEMPORAL_PROCESSOR=${METABONK_COGNITIVE_ENABLE_TEMPORAL_PROCESSOR:-0}
      - METABONK_COGNITIVE_CONTEXT_LEN=${METABONK_COGNITIVE_CONTEXT_LEN:-}
      - METABONK_COGNITIVE_SGLANG_QUANTIZATION=${METABONK_COGNITIVE_SGLANG_QUANTIZATION:-}
      - METABONK_COGNITIVE_SGLANG_DTYPE=${METABONK_COGNITIVE_SGLANG_DTYPE:-}
      - METABONK_COGNITIVE_SGLANG_ATTENTION_BACKEND=${METABONK_COGNITIVE_SGLANG_ATTENTION_BACKEND:-}
      - METABONK_COGNITIVE_SGLANG_MM_ATTENTION_BACKEND=${METABONK_COGNITIVE_SGLANG_MM_ATTENTION_BACKEND:-}
      - METABONK_COGNITIVE_SGLANG_KV_CACHE_DTYPE=${METABONK_COGNITIVE_SGLANG_KV_CACHE_DTYPE:-}
      - METABONK_COGNITIVE_SGLANG_MEM_FRACTION=${METABONK_COGNITIVE_SGLANG_MEM_FRACTION:-}
      - METABONK_COGNITIVE_SGLANG_DISABLE_CUDA_GRAPH=${METABONK_COGNITIVE_SGLANG_DISABLE_CUDA_GRAPH:-}
      - METABONK_COGNITIVE_ENABLE_SDPA_PATCH=${METABONK_COGNITIVE_ENABLE_SDPA_PATCH:-0}
      - METABONK_COGNITIVE_DISABLE_MODEL_OVERLAY=${METABONK_COGNITIVE_DISABLE_MODEL_OVERLAY:-0}
      - METABONK_COGNITIVE_MODEL_OVERLAY_DIR=${METABONK_COGNITIVE_MODEL_OVERLAY_DIR:-/tmp/metabonk_model_overlay}

    volumes:
      # Host model cache: expected to contain a Phi-3 Vision repo folder.
      - "${METABONK_COGNITIVE_MODELS_DIR:-../models}:/models:ro,z"
      # RL logs and server logs.
      - "${METABONK_COGNITIVE_LOG_DIR:-../logs}:/app/logs:rw,z"

    command:
      [
        "python3",
        "cognitive_server.py",
        "--model-path",
        "${METABONK_COGNITIVE_MODEL_PATH:-/models/Phi-3-vision-128k-instruct}",
        "--tp-size",
        "${METABONK_COGNITIVE_TP_SIZE:-1}",
        "--quantization",
        "${METABONK_COGNITIVE_QUANTIZATION:-}",
        "--sglang-port",
        "${METABONK_COGNITIVE_SGLANG_PORT:-30000}",
        "--max-running-requests",
        "${METABONK_COGNITIVE_MAX_REQS:-64}",
        "--zmq-port",
        "${METABONK_COGNITIVE_ZMQ_PORT:-5555}"
      ]
